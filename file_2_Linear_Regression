import matplotlib.pyplot as plt
import numpy as np
train_x = np.array([0.5, 0.6, 0.8, 1.1, 1.4])
train_y = np.array([5.0, 5.5, 6.0, 6.8, 7.0])
w0, w1, losses, epoches = [1], [1], [], []
times = 1000
lrate = 0.05
for i in range(1, times + 1):
    epoches.append(i)
    #求损失值：
    loss = ((w0[-1] + w1[-1]*train_x - train_y)**2).sum()
    losses.append(loss)
    print('{:4}, w0={:}, w1={:}, loss={:}'.format(i, w0[-1], w1[-1], loss))
    # 求损失函数的关于w0和w1的偏导，从而更新新模型参数
    d0 = (w0[-1] + w1[-1]*train_x - train_y).sum()
    d1 = (train_x * (w0[-1] + w1[-1]*train_x - train_y)).sum()
    #根据梯度下降，更新w0和w1
    # w0 = w0[-1] - lrate * d0
    # w1 = w1[-1] - lrate * d1
    w0.append(w0[-1] - lrate * d0)
    w1.append(w1[-1] - lrate * d1)
print("w0:", w0[-1])
print("w1:", w1[-1])
#通过w0和w1绘制回归线，
linex = np.linspace(train_x.min(), train_x.max(), 100)
liney = w1[-1] * linex + w0[-1]

#画线性回归图
plt.figure('Linear Regression', facecolor='lightgray')
plt.title('Linear Regression', fontsize=18)
plt.grid(linestyle=':')
plt.scatter(train_x, train_y, s=80, marker='o', color='blue', label='Samples')
plt.plot(linex, liney, color='orangered', linewidth=2, label='Regression Line')
plt.legend()

#训练过程，变化曲线图
plt.figure('Training Progress', facecolor='lightgray')
plt.title('Training progress', fontsize=18)
plt.subplot(311)
plt.grid(linestyle=':')
plt.ylabel('w0', fontsize=14)
plt.plot(epoches, w0[:-1], color='blue', label='w0')
plt.legend()
plt.tight_layout()

plt.subplot(312)
plt.grid(linestyle=':')
plt.ylabel('w1', fontsize=14)
plt.plot(epoches, w1[:-1], color='blue', label='w1')
plt.legend()
plt.tight_layout()

plt.subplot(313)
plt.grid(linestyle=':')
plt.ylabel('loss', fontsize=14)
plt.plot(epoches, losses, color='green', label='loss')
plt.legend()
plt.tight_layout()

plt.show()
